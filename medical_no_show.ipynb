{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a 'no show' for a medical appointment based on historical data\n",
    "This notebook uses a historical dataset from 2016 to predict someone not showing up for a medical appointment.\n",
    "## Packages\n",
    "The following packages were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input\n",
    "First the dataset was read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows 110527\n",
      "Count of Columns 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID Gender          ScheduledDay  \\\n",
       "0  2.987250e+13        5642903      F  2016-04-29T18:38:08Z   \n",
       "1  5.589978e+14        5642503      M  2016-04-29T16:08:27Z   \n",
       "2  4.262962e+12        5642549      F  2016-04-29T16:19:04Z   \n",
       "3  8.679512e+11        5642828      F  2016-04-29T17:29:31Z   \n",
       "4  8.841186e+12        5642494      F  2016-04-29T16:07:23Z   \n",
       "\n",
       "         AppointmentDay  Age      Neighbourhood  Scholarship  Hipertension  \\\n",
       "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
       "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
       "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
       "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
       "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
       "\n",
       "   Diabetes  Alcoholism  Handcap  SMS_received No-show  \n",
       "0         0           0        0             0      No  \n",
       "1         0           0        0             0      No  \n",
       "2         0           0        0             0      No  \n",
       "3         0           0        0             0      No  \n",
       "4         1           0        0             0      No  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/medical_no_show.csv')\n",
    "print('Count of rows', str(df.shape[0]))\n",
    "print('Count of Columns', str(df.shape[1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we check for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As no missing data was found, we proceeded with verifying the dtypes for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientId         float64\n",
       "AppointmentID       int64\n",
       "Gender             object\n",
       "ScheduledDay       object\n",
       "AppointmentDay     object\n",
       "Age                 int64\n",
       "Neighbourhood      object\n",
       "Scholarship         int64\n",
       "Hipertension        int64\n",
       "Diabetes            int64\n",
       "Alcoholism          int64\n",
       "Handcap             int64\n",
       "SMS_received        int64\n",
       "No-show            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we check how many unique values there are for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientId: 62299\n",
      "AppointmentID: 110527\n",
      "Gender: 2\n",
      "ScheduledDay: 103549\n",
      "AppointmentDay: 27\n",
      "Age: 104\n",
      "Neighbourhood: 81\n",
      "Scholarship: 2\n",
      "Hipertension: 2\n",
      "Diabetes: 2\n",
      "Alcoholism: 2\n",
      "Handcap: 5\n",
      "SMS_received: 2\n",
      "No-show: 2\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i+\":\",len(df[i].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "First all column names are converted lowercase to achieve consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `appointmentid` is set as index for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('appointmentid', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`patientid` needs to be converted to `int`.  \n",
    "`no-show` needs to be converted to `int`.  \n",
    "`gender` needs to be converted to `int`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['patientid'] = df['patientid'].astype('int64')\n",
    "df['no-show'] = df['no-show'].map({'No':0, 'Yes':1})\n",
    "df['gender'] = df['gender'].map({'F':0, 'M':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`neighbourhood` is converted using one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['neighbourhood'])\n",
    "df.columns = df.columns.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of features were added:\n",
    "- `num_app`: count how many previous appointments the patient has had (starting with 0)\n",
    "- `apps_missed`: number of appointments missed previously\n",
    "- `previous_noshow`: percentage of previously missed appointments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_app'] = df.sort_values(by = ['patientid','scheduledday']).groupby(['patientid']).cumcount() + 1\n",
    "df['apps_missed'] = df.sort_values(by = ['patientid','scheduledday']).groupby(['patientid'])['no-show'].cumsum().shift(1, axis = 0)\n",
    "df['noshow_pct'] = df['apps_missed'] / (df.sort_values(by = ['patientid','scheduledday']).groupby(['patientid'])['num_app'].shift(1, axis =0))\n",
    "df['noshow_pct'].fillna(0, inplace = True)\n",
    "df['apps_missed'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of a patient that has had multiple appointments and missed some as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheduledday</th>\n",
       "      <th>no-show</th>\n",
       "      <th>num_app</th>\n",
       "      <th>noshow_pct</th>\n",
       "      <th>apps_missed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appointmentid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5566277</th>\n",
       "      <td>2016-04-11T10:09:42Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640434</th>\n",
       "      <td>2016-04-29T10:43:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640443</th>\n",
       "      <td>2016-04-29T10:44:22Z</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653643</th>\n",
       "      <td>2016-05-03T12:59:01Z</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674766</th>\n",
       "      <td>2016-05-09T11:52:43Z</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685329</th>\n",
       "      <td>2016-05-11T10:10:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685501</th>\n",
       "      <td>2016-05-11T10:30:03Z</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716528</th>\n",
       "      <td>2016-05-18T17:48:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716529</th>\n",
       "      <td>2016-05-18T17:48:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719659</th>\n",
       "      <td>2016-05-19T11:45:34Z</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726818</th>\n",
       "      <td>2016-05-20T14:26:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739407</th>\n",
       "      <td>2016-05-25T13:29:23Z</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       scheduledday  no-show  num_app  noshow_pct  apps_missed\n",
       "appointmentid                                                                 \n",
       "5566277        2016-04-11T10:09:42Z        0        1    0.000000          0.0\n",
       "5640434        2016-04-29T10:43:19Z        0        2    0.000000          0.0\n",
       "5640443        2016-04-29T10:44:22Z        1        3    0.000000          0.0\n",
       "5653643        2016-05-03T12:59:01Z        0        4    0.333333          1.0\n",
       "5674766        2016-05-09T11:52:43Z        1        5    0.250000          1.0\n",
       "5685329        2016-05-11T10:10:16Z        0        6    0.400000          2.0\n",
       "5685501        2016-05-11T10:30:03Z        0        7    0.333333          2.0\n",
       "5716528        2016-05-18T17:48:31Z        0        8    0.285714          2.0\n",
       "5716529        2016-05-18T17:48:31Z        0        9    0.250000          2.0\n",
       "5719659        2016-05-19T11:45:34Z        0       10    0.222222          2.0\n",
       "5726818        2016-05-20T14:26:10Z        0       11    0.200000          2.0\n",
       "5739407        2016-05-25T13:29:23Z        1       12    0.181818          2.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['patientid'] == 838284762259].sort_values(by = ['patientid','scheduledday'])[['scheduledday', 'no-show', 'num_app', 'noshow_pct', 'apps_missed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `scheduledday` and `appointmentday` to the datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scheduledday'] = pd.to_datetime(df['scheduledday']).dt.strftime('%Y-%m-%d')\n",
    "df['scheduledday'] = pd.to_datetime(df['scheduledday'])\n",
    "df['appointmentday'] = pd.to_datetime(df['appointmentday']).dt.strftime('%Y-%m-%d')\n",
    "df['appointmentday'] = pd.to_datetime(df['appointmentday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference between the day that the appointment was scheduled and when the appointment actually occurred.  \n",
    "Next we filter out those that have a difference less than zero, as this is likely erroneous data where the appointment occurred before the scheduled date.  \n",
    "Also, people with an age lower or equal to 0 are filtered out, as these are likely wrong entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_diff'] = (df['appointmentday'] - df['scheduledday']).dt.days\n",
    "# Filter by day_diff\n",
    "df = df[df['day_diff'] >= 0]\n",
    "# Filter by age\n",
    "df = df[df['age'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables are generated for `handcap` in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Categorical\n",
    "df['handcap'] = pd.Categorical(df['handcap'])\n",
    "# Convert to Dummy Variables\n",
    "Handicap = pd.get_dummies(df['handcap'], prefix = 'handicap')\n",
    "df = pd.concat([df, Handicap], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnecessary columns are subsequently dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['scheduledday'], axis=1, inplace=True)\n",
    "df.drop(['appointmentday'], axis=1, inplace=True)\n",
    "df.drop(['handcap'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random seed was set to ensure reproducability of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% of the time people did show up for an appointment, leading to an inbalanced dataset.  \n",
    "Just always predicting 0, therefore already leads to an accuracy of 80%, making this scoring parameter not very useful.\n",
    "As we are more interested in the positive class, average precision is used to evaluate different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.797396\n",
       "1    0.202604\n",
       "Name: no-show, dtype: float64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no-show'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling of the data occurred using a robust scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['no-show'], axis=1)\n",
    "y = df['no-show']\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the dataset is split into a training and test set after shuffling and stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify = y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg precision:  0.3252984899031944\n",
      "acg precision:  0.005361513862354794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "lr = LogisticRegression(solver='newton-cg',)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_train)\n",
    "\n",
    "avg_precision = cross_val_score(estimator = lr, X = X_train, y =y_train, cv = 5, scoring='average_precision')\n",
    "print(\"avg precision: \",np.mean(avg_precision))\n",
    "print(\"acg precision: \",np.std(avg_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg precision:  0.2775209476162753\n",
      "acg precision:  0.002018414599599695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_train)\n",
    "\n",
    "avg_precision = cross_val_score(estimator = knn, X = X_train, y =y_train, cv = 5, scoring='average_precision')\n",
    "print(\"avg precision: \",np.mean(avg_precision))\n",
    "print(\"acg precision: \",np.std(avg_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg precision:  0.23993610677770788\n",
      "acg precision:  0.0018807656178568973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dtc = dtc.predict(X_train)\n",
    "clf_report = classification_report(y_train, y_pred_dtc)\n",
    "\n",
    "avg_precision = cross_val_score(estimator = dtc, X = X_train, y =y_train, cv = 5, scoring='average_precision')\n",
    "print(\"avg precision: \",np.mean(avg_precision))\n",
    "print(\"acg precision: \",np.std(avg_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg precision:  0.3763614078511817\n",
      "acg precision:  0.006303351151190706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rd_clf = RandomForestClassifier()\n",
    "rd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rd_clf = rd_clf.predict(X_train)\n",
    "clf_report = classification_report(y_train, y_pred_rd_clf)\n",
    "\n",
    "avg_precision = cross_val_score(estimator = rd_clf, X = X_train, y =y_train, cv = 5, scoring='average_precision')\n",
    "print(\"avg precision: \",np.mean(avg_precision))\n",
    "print(\"acg precision: \",np.std(avg_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg precision:  0.23951160344975123\n",
      "acg precision:  0.001746407794692656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(base_estimator = dtc)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ada = ada.predict(X_train)\n",
    "clf_report = classification_report(y_train, y_pred_ada)\n",
    "\n",
    "avg_precision = cross_val_score(estimator = ada, X = X_train, y =y_train, cv = 5, scoring='average_precision')\n",
    "print(\"avg precision: \",np.mean(avg_precision))\n",
    "print(\"acg precision: \",np.std(avg_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier seem to be performing the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "from random import random\n",
    "\n",
    "\n",
    "max_depth = list(np.arange(10,1000, 10))\n",
    "max_depth.append(None)\n",
    "n_estimators = list(np.arange(10,1000, 10))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = list(np.arange(5,50, 1))\n",
    "max_features.append(None)\n",
    "max_leaf_nodes = list(np.arange(4,100, 1))\n",
    "max_leaf_nodes.append(None)\n",
    "min_samples_split = list(np.arange(2,30, 1))\n",
    "min_samples_split.append(None)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('reg', RandomForestClassifier())\n",
    "    ])\n",
    "param_grid = [\n",
    "    {\n",
    "        'reg': [RandomForestClassifier(random_state = 123)],\n",
    "        'reg__n_estimators': n_estimators,\n",
    "        'reg__criterion': criterion,\n",
    "        'reg__max_depth': max_depth,\n",
    "        'reg__max_features': max_features,\n",
    "        'reg__warm_start': [True], \n",
    "        'reg__min_samples_split': min_samples_split,\n",
    "        'reg__n_jobs': [-1],\n",
    "        'reg__max_leaf_nodes': max_leaf_nodes,\n",
    "        'reg__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "grid_pipeline = RandomizedSearchCV(pipe,param_grid, cv = KFold(5, random_state=123, shuffle = True), n_jobs=-1, n_iter=5, return_train_score=True, scoring = ['accuracy', 'f1', 'roc_auc', 'average_precision'], refit = 'average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, RobustScaler()),\n",
       "                                             (&#x27;reg&#x27;,\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;reg&#x27;: [RandomForestClassifier(max_depth=170,\n",
       "                                                                        max_features=42,\n",
       "                                                                        max_leaf_nodes=84,\n",
       "                                                                        min_samples_split=29,\n",
       "                                                                        n_estimators=640,\n",
       "                                                                        n_jobs=-1,\n",
       "                                                                        random_state=123,\n",
       "                                                                        warm_star...\n",
       "                                                                    10, 11, 12,\n",
       "                                                                    13, 14, 15,\n",
       "                                                                    16, 17, 18,\n",
       "                                                                    19, 20, 21,\n",
       "                                                                    22, 23, 24,\n",
       "                                                                    25, 26, 27,\n",
       "                                                                    28, 29,\n",
       "                                                                    None],\n",
       "                                         &#x27;reg__n_estimators&#x27;: [10, 20, 30, 40,\n",
       "                                                               50, 60, 70, 80,\n",
       "                                                               90, 100, 110,\n",
       "                                                               120, 130, 140,\n",
       "                                                               150, 160, 170,\n",
       "                                                               180, 190, 200,\n",
       "                                                               210, 220, 230,\n",
       "                                                               240, 250, 260,\n",
       "                                                               270, 280, 290,\n",
       "                                                               300, ...],\n",
       "                                         &#x27;reg__n_jobs&#x27;: [-1],\n",
       "                                         &#x27;reg__warm_start&#x27;: [True]}],\n",
       "                   refit=&#x27;average_precision&#x27;, return_train_score=True,\n",
       "                   scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;, &#x27;roc_auc&#x27;, &#x27;average_precision&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, RobustScaler()),\n",
       "                                             (&#x27;reg&#x27;,\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;reg&#x27;: [RandomForestClassifier(max_depth=170,\n",
       "                                                                        max_features=42,\n",
       "                                                                        max_leaf_nodes=84,\n",
       "                                                                        min_samples_split=29,\n",
       "                                                                        n_estimators=640,\n",
       "                                                                        n_jobs=-1,\n",
       "                                                                        random_state=123,\n",
       "                                                                        warm_star...\n",
       "                                                                    10, 11, 12,\n",
       "                                                                    13, 14, 15,\n",
       "                                                                    16, 17, 18,\n",
       "                                                                    19, 20, 21,\n",
       "                                                                    22, 23, 24,\n",
       "                                                                    25, 26, 27,\n",
       "                                                                    28, 29,\n",
       "                                                                    None],\n",
       "                                         &#x27;reg__n_estimators&#x27;: [10, 20, 30, 40,\n",
       "                                                               50, 60, 70, 80,\n",
       "                                                               90, 100, 110,\n",
       "                                                               120, 130, 140,\n",
       "                                                               150, 160, 170,\n",
       "                                                               180, 190, 200,\n",
       "                                                               210, 220, 230,\n",
       "                                                               240, 250, 260,\n",
       "                                                               270, 280, 290,\n",
       "                                                               300, ...],\n",
       "                                         &#x27;reg__n_jobs&#x27;: [-1],\n",
       "                                         &#x27;reg__warm_start&#x27;: [True]}],\n",
       "                   refit=&#x27;average_precision&#x27;, return_train_score=True,\n",
       "                   scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;, &#x27;roc_auc&#x27;, &#x27;average_precision&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, RobustScaler()), (&#x27;reg&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
       "                                             ('reg',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions=[{'reg': [RandomForestClassifier(max_depth=170,\n",
       "                                                                        max_features=42,\n",
       "                                                                        max_leaf_nodes=84,\n",
       "                                                                        min_samples_split=29,\n",
       "                                                                        n_estimators=640,\n",
       "                                                                        n_jobs=-1,\n",
       "                                                                        random_state=123,\n",
       "                                                                        warm_star...\n",
       "                                                                    10, 11, 12,\n",
       "                                                                    13, 14, 15,\n",
       "                                                                    16, 17, 18,\n",
       "                                                                    19, 20, 21,\n",
       "                                                                    22, 23, 24,\n",
       "                                                                    25, 26, 27,\n",
       "                                                                    28, 29,\n",
       "                                                                    None],\n",
       "                                         'reg__n_estimators': [10, 20, 30, 40,\n",
       "                                                               50, 60, 70, 80,\n",
       "                                                               90, 100, 110,\n",
       "                                                               120, 130, 140,\n",
       "                                                               150, 160, 170,\n",
       "                                                               180, 190, 200,\n",
       "                                                               210, 220, 230,\n",
       "                                                               240, 250, 260,\n",
       "                                                               270, 280, 290,\n",
       "                                                               300, ...],\n",
       "                                         'reg__n_jobs': [-1],\n",
       "                                         'reg__warm_start': [True]}],\n",
       "                   refit='average_precision', return_train_score=True,\n",
       "                   scoring=['accuracy', 'f1', 'roc_auc', 'average_precision'])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg__warm_start': True,\n",
       " 'reg__n_jobs': -1,\n",
       " 'reg__n_estimators': 20,\n",
       " 'reg__max_depth': 160,\n",
       " 'reg__bootstrap': True,\n",
       " 'reg': RandomForestClassifier(max_depth=160, n_estimators=20, n_jobs=-1,\n",
       "                        random_state=123, warm_start=True)}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8\n",
      "F1 score is: 0.09\n",
      "ROC AUC is: 0.74\n",
      "Average precision is: 0.4\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is: {}'.format(round(np.nanmax(grid_pipeline.cv_results_['mean_test_accuracy']), 2)))\n",
    "print('F1 score is: {}'.format(round(np.nanmax(grid_pipeline.cv_results_['mean_test_f1']), 2)))\n",
    "print('ROC AUC is: {}'.format(round(np.nanmax(grid_pipeline.cv_results_['mean_test_roc_auc']), 2)))\n",
    "print('Average precision is: {}'.format(round(np.nanmax(grid_pipeline.cv_results_['mean_test_average_precision']), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the test set, the model performs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89     21327\n",
      "           1       0.67      0.05      0.09      5419\n",
      "\n",
      "    accuracy                           0.80     26746\n",
      "   macro avg       0.74      0.52      0.49     26746\n",
      "weighted avg       0.78      0.80      0.73     26746\n",
      "\n",
      "Average precision is : 0.22\n"
     ]
    }
   ],
   "source": [
    "grid_pipeline_pred = grid_pipeline.predict(X_test)\n",
    "clf_report = classification_report(y_test, grid_pipeline_pred)\n",
    "print(f\"Classification Report : \\n{clf_report}\")\n",
    "print(f\"Average precision is : {round(metrics.average_precision_score(y_test, grid_pipeline.predict(X_test)), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21327\n",
       "1     5419\n",
       "Name: no-show, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('no_show')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c9ed330dc4982e09f32666d7534e0f15b7a186942a9037d256fcd790c7c86e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
